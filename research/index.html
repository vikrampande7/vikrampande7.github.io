<!DOCTYPE html>
<html>
  <head>
    <title>Vikram Pande</title>
    <base target="_blank">

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <!-- <meta name="description" content="Electrical Engineering Dual-Degree Student, IIT Bombay">
    <meta property="og:description" content="Electrical Engineering Dual-Degree Student, IIT Bombay" /> -->
    
    <meta name="author" content="Vikram Pande" />

    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
<!--     <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,400,700" rel="stylesheet"> -->
    <link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">
    <link rel="alternate" type="application/rss+xml" title="Vikram Pande - Data Scientist/Machine Learning Engineer" href="/feed.xml" />
    <link rel="icon" type="image/png" href="/metadata/me_pixar_face.png">
    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          
          <div class="site-info">
            <h1 class="site-name"><a href="/" target="_self">Vikram Pande</a></h1>
            <!-- <p class="site-description">Electrical Engineering Dual-Degree Student, IIT Bombay</p> -->
          </div>

          <nav>
            <a href="/about" target="_self">About</a>
            <a href="/research" target="_self">Projects</a>
            <a href="/blog" target="_self">Blog</a>
            <a href="/metadata/Vikram Resume 2025.pdf">CV</a>
            <a href="/misc/">Misc</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Interests</h1>

  <div class="entry">
    <p>My interests lie in Machine Learning & AI, Natural Language Processing, Multimodal AI, and scalable, production-level machine learning systems.</p>

<h3 id="projects">Projects and Research</h3> 

<style>
.papers-list {
  margin-left: 1.5rem; /* Indent projects from header */
}

.papers-list ul {
  padding-left: 1rem;
  list-style: disc; /* Show bullet points */
}

.papers-list li {
  margin-bottom: 0.8rem;
  padding: 0.3rem 0;
}

h3 {
  margin: 0.2em 0;
  font-size: 1em;
  font-weight: bold;
}

.links {
  margin-top: 0.2rem;
  display: flex;
  gap: 1rem;
}

.abstract {
  display: none;
  margin: 0.3rem 0;
  color: #444;
  font-size: 0.9em;
  line-height: 1.4;
}

.abstract.active {
  display: block;
}

.abstract-link {
  cursor: pointer;
  color: #0366d6;
  text-decoration: none;
  font-size: 0.9em;
}

.code-link {
  font-size: 0.9em;
}

/* Remove border between items */
.papers-list li {
  border-bottom: none;
  padding: 0.2rem 0;
}
</style>

<div class="papers-list">
  <ul>
    <li>
      <h3><a href="https://github.com/vikrampande7/deepfake-detection">DeepFake Detection using Explainable AI</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://github.com/vikrampande7/deepfake-detection">[Code]</a>
        <a class="code-link" href="/metadata/deepfake-poster.png">[Poster]</a>
      </div>
      <div class="abstract">
        <p>Implemented deepfake detection model using XceptionNet with explainable AI (LIME and GradCam). Processed FaceForensic++ and Celeb-DF datasets by extracting frames from videos. Focused on interpretability through visualization of model decision-making.</p>
      </div>
    </li>

    <li>
      <h3><a href="https://arxiv.org/pdf/2408.06335">LOLgorithm</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://psvkaushik.github.io/proj/index.html">[Project Page]</a>
        <a class="code-link" href="https://github.com/vikrampande7/LOLgorithm">[Code]</a>
      </div>
      <div class="abstract">
        <p>Humor is a fascinating and puzzling area of study in the field of computers understanding human language. 
          The aim of this project was to understand how syntactic, semantic and contextual embeddings affect the performance of model and whether combining them together result into better model predictions.</p>
      </div>
    </li>

    <li>
      <h3><a href="https://github.com/vikrampande7/prompt-engineering/tree/main">News Classification with LLMs and Prompt Engineering</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://github.com/vikrampande7/prompt-engineering/blob/main/vspande_report.pdf">[Report]</a>
        <a class="code-link" href="https://github.com/vikrampande7/prompt-engineering/tree/main">[Code]</a>
      </div>
      <div class="abstract">
        <p>News classification is of importance in the field of information retrieval and media analysis.
          Dataset: AG News (AG’s News Corpus): : It contains 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1900 testing samples and the total number of training samples is 120,000 and testing samples is 7,600. The classes are divided into categories: world, sports, business, and science/technology.
          Prompting Strategy
          Baseline:
          Large Language Models (LLMs) are typically trained on extensive datasets, allowing them to work effectively with direct inputs and outputs. When prompted directly, an LLM can often generate a reasonably accurate response in a single attempt. 
          This approach is referred to as “zero-shot prompting” and is considered a baseline technique in prompt engineering. 
          In simple terms, the model is presented with a straightforward question without any surrounding context or background information, and it is expected to provide a corresponding answer. The extended version would be “few-shot-prompting”.
          (1)Few-shot prompting:
          In few-shot prompting, only a small number of examples/shots are also provided in prompt. This helps model in decision making for new data and useful when annotated data is limited to guide its understanding of a particular task or generate desired responses.
          (2)Chain-of-thought (CoT):
          (3)Chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. To maintain a coherent flow of conversation. Instead of asking isolated or individual questions, this approach involves generating prompts that build upon the previous responses or questions, forming a logical and connected chain of thought in the conversation.
          Zero Shot Chain-of-thought (CoT):
          A novel concept, the zero-shot CoT (Kojima et al. 2022), introduces a distinct approach by incorporating the phrase “Let’s think step by step” into the original prompt. This strategy aims to enhance model performance. This approach empowers the model with the capacity to engage in systematic and logical reasoning. By introducing the directive to “think step by step,” it encourages the model to break down complex problems into manageable components, facilitating more coherent and reasoned responses.</p>
      </div>
    </li>

        <li>
      <h3><a href="TBD">EEG-based Activity Recognition</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="/metadata/10_P4_EEG_ActivityRecognition.pdf">[Slides]</a>
        <a class="code-link" href="TBD">[Code]</a>
      </div>
      <div class="abstract">
        <p>Electroencephalograms (EEGs) can record electricalactivity in the brain. They can be used to augment human sensory functions or control robotic devices. In order to perform these functions the Brain Computer Interface (BCI) must be able to classify EEG patterns as corresponding to a certain task and relay that information to control the device of interest.
          This project focuses on the BCI competition III Dataset V in which the goal is to classify three mental tasks online. There are 3 tasks:
          Imagination of repetitive self-paced left hand movements, (left, class 2),
          Imagination of repetitive self-paced right hand movements, (right, class 3),
          Generation of words beginning with the same random letter, (word, class 7).
          BCI Competition iii Dataset V: 32 Electrodes to collect EEG data.
          EEG: ElectroEncephaloGraphy - method to record an electrogram of the spontaneous electrical activity of the brain.
          Sampling rate is 512 Hz.
          Modeling Techniques used: SVM, kNN, Hidden Markov Models, LSTM, BiLSTM</p>
      </div>
    </li>

        <li>
      <h3><a href="https://github.com/vikrampande7/SingleViewMetrology">3D Reconstruction with Single View Metrology</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://github.com/vikrampande7/SingleViewMetrology/blob/main/REPORT_Project01.pdf">[Report]</a>
        <a class="code-link" href="https://github.com/vikrampande7/SingleViewMetrology">[Code]</a>
      </div>
      <div class="abstract">
        <p>This project was a part of coursework ECE 558 - Digital Imaging Systems at NC State which mainly focuses on the implementation of the paper “single view metrology” (Criminisi, Reid and Zisserman, ICCV99) to convert a 2D image into 3D model.
          The Project is divided into 4 sub parts.
          The first part is the 3D perspective image acquisition. - Second part is to calculate the Vanish points in the given image related to objects.
          Third part focuses on calculating the Projection and Homograph Matrices.
          Fourth part focuses on getting a texture map for each plane using warping.
          At last, the visualisation of 3D object with Blender is done.</p>
      </div>
    </li>

    <li>
      <h3><a href="https://github.com/vikrampande7/blob-detector">Blob Detection</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://github.com/vikrampande7/blob-detector/blob/main/ECE%20558%20FINAL%20PROJECT%20REPORT.pdf">[Report]</a>
        <a class="code-link" href="https://github.com/vikrampande7/blob-detector">[Code]</a>
      </div>
      <div class="abstract">
        <p>Blob detection is a major component in the fields on Image Processing and Computer Vision. In this project, a blob detector with statistical steps was implemented from scratch.
            Generated Laplacian of Gaussian filter. Generated Laplacian Scale Space with Convolution. Performed Non-Max-Suppression. Drawn circles around maxima points.</p>
      </div>
    </li>

    <li>
      <h3><a href="https://github.com/vikrampande7/terrain-detection">Terrain Identification</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://github.com/vikrampande7/terrain-detection">[Code]</a>
      </div>
      <div class="abstract">
        <p>The ability to walk efficiently, safely, and attentively is a natural human trait that is disrupted by lower limb amputations. To restore basic walking function, amputees often rely on prosthetic devices. 
          This project focuses on developing a system that identifies the terrain using data from inertial measurement units (IMUs) in the prosthetic leg.
          The training data includes the following 4 classes: (0) indicates standing or walking on solid ground, (1) indicates going down the stairs, (2) indicates going up the stairs, and (3) indicates walking on grass. For different users, multiple sessions were conducted with a start time of 0. We combined all labels for visualization. It can be observed that there is a class imbalance with class 0 having the maximum number of instances.
          Classification using sequential data was done using LSTM and its variants.</p>
      </div>
    </li>

    <li>
      <h3><a href="/metadata/Report.pdf">Video Streaming Service on AWS</a></h3>
      <div class="links">
        <a class="abstract-link" onclick="toggleAbstract(this)">[Abstract]</a>
        <a class="code-link" href="https://github.com/vikrampande7/cloud-computing">[Code]</a>
        <a class="code-link" href="/metadata/Report.pdf">[Report]</a>
      </div>
      <div class="abstract">
        <p>The primary objective of this project was to understand and delve deeper into the fundamental concepts of cloud computing and its associated components.
            Cloud computing, an ever-evolving field and is useful in Machine Learning and AI as well.
            This technical document is written from the perspective of a cloud architect, encompassing comprehensive aspects in the design of end-to-end cloud applications and services.
            The project unfolds across several sections, with a focus on developing a Video Streaming Platform-as-a-Service, same as Netflix:
            (1) Define business requirements and link them to corresponding technical requirements, justifying the necessity of each technical requirement for a specific business need.
            (2)Discuss trade-offs between business requirements, acknowledging the engineering constraints No free lunch in engineering.
            (3)Compare different major cloud service providers and select AWS based on varied criteria for the video streaming service.
            (4)Detail the foundational building blocks of the design, explaining the corresponding AWS services. Comparison of these cloud providers.
            (5)Reference of the AWS well architected framework.
            (6)Present an architectural diagram, discussing the six pillars outlined in AWS documentation.
            (7)Additionally, incorporate design principles and best practices.
            (8)Conduct an experiment using Kubernetes to explore load balancing and autoscaling. Employ Locust to generate load and observe the autoscaling of K8s pods in response to load fluctuations.
            The project extensively references AWS pillar documentation for comprehensive insights into cloud architecture.</p>
      </div>
    </li>

    
  </ul>
</div>

<script>
function toggleAbstract(link) {
  const abstractDiv = link.parentElement.nextElementSibling;
  abstractDiv.classList.toggle('active');
  link.textContent = abstractDiv.classList.contains('active') ? 'Hide Abstract' : 'Abstract';
}
</script>

<h4>For more projects, please refer to my <a href="https://github.com/vikrampande7">GitHub</a>.</h4>

  </div>

</article>
</div>


<div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
<!-- <div style="float:left;color:#808080">Archiki Prasad<br style="clear:both" /> </div> -->
<div class="row">
<div class="column"><a style="float:left;color:#808080"><span>Vikram Pande</span></a>
<br style="clear:both" />
<a href="mailto:vikrampande783@gmail.com" style="float:left;font-weight:lighter;"><span>vikrampande783@gmail.com</span></a>
<br style="clear:both" />
<a href="mailto:vspande.ncsu.edu" style="float:left;font-weight:lighter;"><span>vspande.ncsu.edu</span></a>
</div>
<!-- <div class="row"> -->
<div class="column">
<a href="https://github.com/vikrampande7" style="float:left;font-weight:lighter;"><span class="icon icon--github"><svg x="0px" y="0px" width="16px" height="16px" viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">vikrampande7</span></a>
<br style="clear:both" />
<a href="https://www.linkedin.com/in/vikrampande7/" style="float:left;font-weight:lighter;"><span class="icon icon--linkedin"><svg  x="0px" y="0px" width="16px" height="16px" viewBox="0 -20 512 512"><path fill="#828282" d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683
    C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z
    M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615
    c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915
    s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z"/></svg></span><span class="username">&nbsp;Vikram Pande</span></a>
<br style="clear:both" />
<a href="https://x.com/VikramPande007" style="float:left;font-weight:lighter;"><span class="icon icon--twitter"><svg x="0px" y="0px" width="16px" height="16px" viewBox="0 -6 20 20"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
</svg></span><span class="username">&nbsp;Vikram Pande</span></a>
<br style="clear:both" />

<!-- Medium Link -->
<a href="https://medium.com/@vikrampande783" style="float:left; font-weight:lighter; display:flex; align-items:center; gap:4px;">
  <span class="icon icon--medium" style="display:flex; align-items:center;">
    <svg width="14" height="14" viewBox="0 0 1043.63 592.71" xmlns="http://www.w3.org/2000/svg">
      <path fill="#828282" d="M588.67 296.35c0 163.7-131.19 296.35-293.34 296.35S2 460.05 2 296.35 133.19 0 295.33 0s293.34 132.65 293.34 296.35zm316.96 0c0 154.13-65.64 279.22-146.6 279.22s-146.59-125.09-146.59-279.22 65.63-279.22 146.59-279.22 146.6 125.09 146.6 279.22zm137.96 0c0 144.41-24.57 261.47-54.9 261.47s-54.9-117.06-54.9-261.47 24.56-261.47 54.9-261.47 54.9 117.06 54.9 261.47z"/>
    </svg>
  </span>
  <span class="username">vikrampande783</span>
</a>
<br style="clear:both" />

<!-- LeetCode Link -->
<a href="https://leetcode.com/vikrampande7/" style="float:left; font-weight:lighter; display:flex; align-items:center; gap:4px;">
  <span class="icon icon--leetcode" style="display:flex; align-items:center;">
    <svg width="14" height="14" viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
      <path fill="#828282" d="M50,2C23.49,2,2,23.49,2,50s21.49,48,48,48s48-21.49,48-48S76.51,2,50,2z M50,90c-22.06,0-40-17.94-40-40 S27.94,10,50,10s40,17.94,40,40S72.06,90,50,90z"/>
      <path fill="#828282" d="M63.5,29.5c-1.38,0-2.5,1.12-2.5,2.5v14h-22v-14c0-1.38-1.12-2.5-2.5-2.5S34,30.62,34,32v36 c0,1.38,1.12,2.5,2.5,2.5s2.5-1.12,2.5-2.5v-14h22v14c0,1.38,1.12,2.5,2.5,2.5s2.5-1.12,2.5-2.5v-36C66,30.62,64.88,29.5,63.5,29.5 z"/>
    </svg>
  </span>
  <span class="username">vikrampande7</span>
</a> 

</div>
</div>


        </footer>
      </div>
    </div>
   

  </body>
</html>
